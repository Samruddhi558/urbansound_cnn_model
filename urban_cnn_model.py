# -*- coding: utf-8 -*-
"""Urban_cnn_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/AmritK10/Urban-Sound-Classification/blob/master/Urban_cnn_model.ipynb

# Urban Sound Classification - CNN Model

## Mount Drive
"""

# mount drive with data
from google.colab import drive
drive.mount('/content/gdrive')

"""## Fetch Processed Data"""

#extracting data from pkl files
import pickle as pkl

with open("/content/gdrive/My Drive/UrbanSound8k/x_data.pickle","rb") as f:
  x_data = pkl.load(f)

with open("/content/gdrive/My Drive/UrbanSound8k/y_label.pickle","rb") as f:
  y_label = pkl.load(f)

#reshape data
import numpy as np
from keras.utils.np_utils import to_categorical

X = []
Y = []
for i in range(10):
  xi = np.array(x_data[i])

  #reshaping to shape required by CNN
  xi_cnn = np.reshape(xi,(xi.shape[0],xi.shape[1],xi.shape[2], 1))
  X.append(xi_cnn)

  yi = to_categorical(y_label[i], num_classes=10)
  Y.append(yi)

#shape
X[0].shape, Y[0].shape

"""## Build Model"""

from keras import Sequential
from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout,Activation
from keras.regularizers import l2

def get_model():
  #forming model
  model = Sequential()

  #adding layers and forming the model
  model.add(Conv2D(64,kernel_size=5,strides=1,padding="Same",activation="relu",input_shape=(36,5,1)))
  model.add(MaxPooling2D(padding="same"))

  model.add(Conv2D(128,kernel_size=5,strides=1,padding="same",activation="relu"))
  model.add(MaxPooling2D(padding="same"))
  model.add(Dropout(0.3))

  model.add(Flatten())

  model.add(Dense(512,activation="relu"))
  model.add(Dropout(0.4))

  model.add(Dense(512,activation="relu"))
  model.add(Dropout(0.4))

  model.add(Dense(10,activation="softmax"))

  #compiling
  model.compile(optimizer="adam",loss="categorical_crossentropy",metrics=["accuracy"])

  return model

"""## 10-fold Cross Validation"""

sum_train_loss = 0
sum_test_loss = 0
sum_train_acc = 0
sum_test_acc = 0

for i in range(10):
  model = get_model()

  x_train = np.concatenate([X[j] for j in [k for k in range(10) if k not in [i]]])
  y_train = np.concatenate([Y[j] for j in [k for k in range(10) if k not in [i]]])

  x_test = X[i]
  y_test = Y[i]

  model.fit(x_train, y_train, epochs=30, batch_size=50)

  #train and test loss and scores respectively
  train_eval = model.evaluate(x_train, y_train)
  test_eval = model.evaluate(x_test, y_test)

  print("Results for folder: ", i)
  print(train_eval)
  print(test_eval)

  sum_train_loss += train_eval[0]
  sum_test_loss += test_eval[0]
  sum_train_acc += train_eval[1]
  sum_test_acc += test_eval[1]

"""## Results"""

#train and test scores
print("Avg Train Loss: ", sum_train_loss/10)
print("Avg Train Acc: ", sum_train_acc/10)
print("Avg Test Loss Score: ", sum_test_loss/10)
print("Avg Test Loss Acc: ", sum_test_acc/10)

"""## Augmented Data

### Fetch Data
"""

X_original = X
Y_original = Y

#extracting data from pkl files
with open("/content/gdrive/My Drive/UrbanSound8k/x_aug_data.pickle","rb") as f:
  x_aug_data = pkl.load(f)

with open("/content/gdrive/My Drive/UrbanSound8k/y_aug_label.pickle","rb") as f:
  y_aug_label = pkl.load(f)

#reshape data
import numpy as np
from keras.utils.np_utils import to_categorical

X = []
Y = []
for i in range(10):
  xi = np.array(x_aug_data[i])

  #reshaping to shape required by CNN
  xi_cnn = np.reshape(xi,(xi.shape[0],xi.shape[1],xi.shape[2], 1))
  X.append(xi_cnn)

  yi = to_categorical(y_aug_label[i], num_classes=10)
  Y.append(yi)

#shape
X[0].shape, Y[0].shape

"""### 10-fold Cross Validation"""

sum_train_loss = 0
sum_test_loss = 0
sum_train_acc = 0
sum_test_acc = 0

for i in range(10):
  model = get_model()

  x_train = np.concatenate([X[j] for j in [k for k in range(10) if k not in [i]]])
  y_train = np.concatenate([Y[j] for j in [k for k in range(10) if k not in [i]]])

  x_test = X_original[i]
  y_test = Y_original[i]

  model.fit(x_train, y_train, epochs=30, batch_size=50)

  #train and test loss and scores respectively
  train_eval = model.evaluate(x_train, y_train)
  test_eval = model.evaluate(x_test, y_test)

  print("Results for folder: ", i)
  print(train_eval)
  print(test_eval)

  sum_train_loss += train_eval[0]
  sum_test_loss += test_eval[0]
  sum_train_acc += train_eval[1]
  sum_test_acc += test_eval[1]

"""### Results"""

#train and test scores
print("Avg Train Loss: ", sum_train_loss/10)
print("Avg Train Acc: ", sum_train_acc/10)
print("Avg Test Loss Score: ", sum_test_loss/10)
print("Avg Test Loss Acc: ", sum_test_acc/10)